{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating news headline with Recurrent Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates NLP pipeline for news headline generation based on the framework explained in this  <a href=\"https://nlp.stanford.edu/courses/cs224n/2015/reports/1.pdf\">paper</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Chainer Framework\n",
    "import chainer\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import reporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LSTMBlock is a fundamental unit of the model described in the aforementioned paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMBlock(chainer.ChainList):\n",
    "    def __init__(self, num_layers, num_hidden, dropout_ratio=0.5):\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "\n",
    "        layers = [L.LSTM(num_hidden, num_hidden) for _ in range(num_layers)]\n",
    "\n",
    "        super(LSTMBlock, self).__init__(*layers)\n",
    "\n",
    "    def reset_state(self):\n",
    "        for i in range(self.num_layers):\n",
    "            self[i].reset_state()\n",
    "\n",
    "    def __call__(self, x, train):\n",
    "        output = x\n",
    "        for i in range(self.num_layers):\n",
    "            output = self[i](\n",
    "                F.dropout(\n",
    "                    output,\n",
    "                    ratio=self.dropout_ratio,\n",
    "                    train=train\n",
    "                )\n",
    "            )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMNet(chainer.Chain):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_rnn_layers, num_hidden,\n",
    "            vocab_size,\n",
    "            dropout_ratio=0.5):\n",
    "        super(LSTMNet, self).__init__(\n",
    "            embed=L.EmbedID(vocab_size, num_hidden),\n",
    "            cell=LSTMBlock(num_rnn_layers, num_hidden, dropout_ratio),\n",
    "        )\n",
    "\n",
    "    def __call__(self, xs, train):\n",
    "        self.cell.reset_state()\n",
    "        embeddings = self.embed(xs)\n",
    "        return [self.cell(embeddings[:, i, :], train) for i in\n",
    "                range(embeddings.shape[1])]\n",
    "\n",
    "    def predict(self, xs, ys, train):\n",
    "        outputs = self.__call__(xs, ys, train)\n",
    "        return self.linear(F.concat(outputs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(chainer.Chain):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_encode_rnn_layers, num_decode_rnn_layers, num_hidden,\n",
    "            vocab_size,\n",
    "            dropout_ratio=0.5):\n",
    "        super(EncoderDecoder, self).__init__(\n",
    "            encoder=LSTMNet(\n",
    "                        num_encode_rnn_layers, num_hidden, vocab_size,\n",
    "                        dropout_ratio\n",
    "                    ),\n",
    "            decoder_cell=LSTMBlock(\n",
    "                        num_decode_rnn_layers, num_hidden,\n",
    "                        dropout_ratio\n",
    "                    ),\n",
    "            linear=L.Linear(num_hidden, vocab_size)\n",
    "        )\n",
    "\n",
    "    def __call__(self, xs, ys, train):\n",
    "        encoder_hidden = self.encoder(xs, train)[-1]\n",
    "\n",
    "        self.decoder_cell.reset_state()\n",
    "        ys_embeddings = self.encoder.embed(ys)\n",
    "        length = ys_embeddings.shape[1]\n",
    "        outputs = []\n",
    "        output = self.xp.zeros(\n",
    "                    (xs.shape[0], self.decoder_cell[0].state_size),\n",
    "                    dtype=self.xp.float32\n",
    "                )\n",
    "        for i in range(length):\n",
    "            if i > 0:\n",
    "                decoder_inputs = encoder_hidden + ys_embeddings[:, i - 1, :]\n",
    "            else:\n",
    "                decoder_inputs = encoder_hidden\n",
    "            output = self.decoder_cell(decoder_inputs, train)\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "    def predict(self, xs, ys, train):\n",
    "        outputs = self.__call__(xs, ys, train)\n",
    "        return self.linear(F.concat(outputs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GlobalAttention(chainer.Chain):\n",
    "    def __init__(self, num_hidden):\n",
    "        super(GlobalAttention, self).__init__(\n",
    "            w1=L.Linear(num_hidden, num_hidden),\n",
    "            w2=L.Linear(num_hidden, num_hidden),\n",
    "            v=L.Linear(num_hidden, 1)\n",
    "        )\n",
    "        self.encoder_hiddens = None\n",
    "        self.w1hi = None\n",
    "\n",
    "    def __call__(self, output_hidden, length):\n",
    "        batch_size = output_hidden.shape[0]\n",
    "        num_hidden = output_hidden.shape[1]\n",
    "\n",
    "        w2dt = F.broadcast_to(\n",
    "                self.w2(output_hidden),\n",
    "                shape=(length, batch_size, num_hidden)\n",
    "            )\n",
    "        w1hi_plus_w2dt = self.w1hi + w2dt\n",
    "        w1hi_plus_w2dt = F.swapaxes(w1hi_plus_w2dt, 0, 1)\n",
    "        w1hi_plus_w2dt = F.reshape(\n",
    "                            w1hi_plus_w2dt,\n",
    "                            shape=(batch_size * length, -1)\n",
    "                        )\n",
    "\n",
    "        logits = F.reshape(\n",
    "                    self.v(F.tanh(w1hi_plus_w2dt)),\n",
    "                    shape=(batch_size, -1)\n",
    "                )\n",
    "\n",
    "        probs = F.broadcast_to(\n",
    "                    F.softmax(logits),\n",
    "                    shape=(num_hidden, batch_size, length)\n",
    "                )\n",
    "\n",
    "        probs = F.swapaxes(probs, 0, 2)\n",
    "\n",
    "        return F.sum(self.encoder_hiddens * probs, axis=0)\n",
    "\n",
    "    def precompute(self, encoder_hiddens):\n",
    "        length = len(encoder_hiddens)\n",
    "        batch_size = encoder_hiddens[0].shape[0]\n",
    "        self.encoder_hiddens = F.stack(encoder_hiddens)\n",
    "        self.w1hi = F.reshape(\n",
    "                self.w1(F.reshape(self.encoder_hiddens,\n",
    "                        shape=(length * batch_size, -1))),\n",
    "                shape=(length, batch_size, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionalEncoderDecoder(EncoderDecoder):\n",
    "    def __init__(\n",
    "            self, attention_model, num_encode_rnn_layers,\n",
    "            num_decode_rnn_layers, num_hidden, vocab_size, dropout_ratio=0.5):\n",
    "        super(AttentionalEncoderDecoder, self).__init__(\n",
    "                num_encode_rnn_layers,\n",
    "                num_encode_rnn_layers, num_hidden, vocab_size, dropout_ratio\n",
    "            )\n",
    "        self.add_link(\"attention\", attention_model)\n",
    "\n",
    "    def __call__(self, xs, ys, train):\n",
    "        self.attention.precompute(self.encoder(xs, train))\n",
    "\n",
    "        self.decoder_cell.reset_state()\n",
    "        ys_embeddings = self.encoder.embed(ys)\n",
    "        length = ys_embeddings.shape[1]\n",
    "        outputs = []\n",
    "        output = self.xp.zeros(\n",
    "                    (xs.shape[0], self.decoder_cell[0].state_size),\n",
    "                    dtype=self.xp.float32\n",
    "                )\n",
    "        for i in range(length):\n",
    "            decoder_inputs = self.attention(output, length)\n",
    "            if i > 0:\n",
    "                decoder_inputs += ys_embeddings[:, i - 1, :]\n",
    "            output = self.decoder_cell(decoder_inputs, train)\n",
    "            outputs.append(output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HeadlineGeneratorClassifier(chainer.Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(HeadlineGeneratorClassifier, self).__init__(predictor=predictor)\n",
    "\n",
    "    def __call__(self, xs, ys, train):\n",
    "        decoder_logits = self.predictor.predict(xs, ys, train)\n",
    "        labels = F.flatten(F.transpose(ys))\n",
    "        loss = F.softmax_cross_entropy(decoder_logits, labels)\n",
    "        accuracy = F.accuracy(decoder_logits, labels)\n",
    "        reporter.report({\"loss\": loss, \"accuracy\": accuracy}, self)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET ITERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DSIterator(chainer.dataset.Iterator):\n",
    "    def __init__(\n",
    "            self,\n",
    "            xp,\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            eos, pad,\n",
    "            shuffle=True, repeat=True):\n",
    "        self.xp = xp\n",
    "        self.dataset = dataset\n",
    "        self.size = len(dataset)\n",
    "        self.batch_size = batch_size\n",
    "        assert batch_size <= self.size\n",
    "        self.eos = eos\n",
    "        self.pad = pad\n",
    "        self.shuffle = shuffle\n",
    "        self.repeat = repeat\n",
    "\n",
    "        self.epoch = 0\n",
    "        self.is_new_epoch = False\n",
    "        self.iteration = 0\n",
    "        self.offset = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        self.is_new_epoch = (self.offset == 0)\n",
    "        if self.is_new_epoch:\n",
    "            self.epoch += 1\n",
    "            if self.shuffle:\n",
    "                random.shuffle(self.dataset)\n",
    "            if not self.repeat and self.epoch > 1:\n",
    "                raise StopIteration\n",
    "\n",
    "        next_offset = min(self.size, self.offset + self.batch_size)\n",
    "        batch = self.dataset[self.offset: next_offset]\n",
    "        assert len(batch) > 0\n",
    "        assert len(batch) == self.batch_size or (next_offset == self.size and\n",
    "                len(batch) == self.size - self.offset)\n",
    "        self.offset = next_offset if next_offset < self.size else 0\n",
    "\n",
    "        # Padding\n",
    "        max_x_length = max([len(pair[0]) for pair in batch])\n",
    "        max_y_length = max([len(pair[1]) for pair in batch])\n",
    "\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for x, y in batch:\n",
    "            x_batch.append(\n",
    "                x + [self.eos] + [self.pad] * (max_x_length - len(x))\n",
    "            )\n",
    "            y_batch.append(\n",
    "                y + [self.eos] + [self.pad] * (max_y_length - len(y))\n",
    "            )\n",
    "        x_batch = self.xp.array(x_batch, dtype=np.int32)\n",
    "        y_batch = self.xp.array(y_batch, dtype=np.int32)\n",
    "        return x_batch, y_batch\n",
    "\n",
    "    @property\n",
    "    def epoch_detail(self):\n",
    "        return self.epoch + (self.offset * 1.0 / self.size)\n",
    "\n",
    "    def serialize(self, serializer):\n",
    "        self.iteration = serializer(\"iteration\", self.iteration)\n",
    "        self.epoch = serializer(\"self.epoch\", self.epoch)\n",
    "        self.offset = serializer(\"self.offset\", self.offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class HeadlineGeneratorUpdater(chainer.training.StandardUpdater):\n",
    "    def __init__(self, data_iter, optimizer, device):\n",
    "        super(HeadlineGeneratorUpdater, self).__init__(\n",
    "            data_iter, optimizer, device=device\n",
    "        )\n",
    "\n",
    "    def update_core(self):\n",
    "        data_iter = self.get_iterator(\"main\")\n",
    "        optimizer = self.get_optimizer(\"main\")\n",
    "        x_batch, y_batch = data_iter.__next__()\n",
    "        loss = optimizer.target(x_batch, y_batch, train=True)\n",
    "        optimizer.target.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7  # SPLITTING DATASET INTO TRAINING.  \n",
    "VALID_SIZE = 0.3  # AND VALIDATION.\n",
    "MAX_STRING_LEN = 140\n",
    "NUM_ENCODE_LAYERS = 3 # NUMBER OF LSTM BLOCKS IN THE ENCODER\n",
    "NUM_DECODE_LAYERS = 3 # NUMBER OF LSTM BLOCKS IN THE DECODER.\n",
    "NUM_HIDDEN = 128 # HIDDEN UNITS IN A LSTM BLOCK.\n",
    "BATCH_SIZE = 1 # BATCH SIZE 1 FOR CPU, 128 FOR GPU.\n",
    "NUM_EPOCHS = 20 \n",
    "DROPOUT = 0.5\n",
    "DEVICE = -1 # -1 = CPU; [0, N] FOR GPU.\n",
    "DS_PATH = './dataset/news_summary.csv'\n",
    "GRADIENT_CLIP = 5\n",
    "LOG = \"./log\"\n",
    "EOS = \"<eos>\"\n",
    "PAD = \"<pad>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENERATING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_word_id_map(path):\n",
    "    word_id_map = {}\n",
    "    with open(path, 'r', encoding='latin-1') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            complete_text = row['ctext'].lower()\n",
    "            summary = row['text'].lower()\n",
    "            for _idx, x in enumerate(complete_text.split(' ')):\n",
    "                if x not in word_id_map:\n",
    "                    word_id_map[x] = len(word_id_map)\n",
    "\n",
    "            for _idx, x in enumerate(summary.split(' ')):\n",
    "                if x not in word_id_map:\n",
    "                    word_id_map[x] = len(word_id_map)\n",
    "    word_id_map[EOS] = len(word_id_map)\n",
    "    word_id_map[PAD] = len(word_id_map)\n",
    "    return word_id_map\n",
    "\n",
    "\n",
    "def gen_dataset(word_id_map, path):\n",
    "    train = []\n",
    "    with open(path, 'r', encoding='latin-1') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            complete_text = row['ctext'].lower()\n",
    "            summary = row['text'].lower()\n",
    "            inp = [\n",
    "                    word_id_map[x]\n",
    "                    for _idx, x in enumerate(complete_text.split(' '))\n",
    "                ]\n",
    "            tar = [\n",
    "                    word_id_map[x]\n",
    "                    for _idx, x in enumerate(summary.split(' '))\n",
    "                ]\n",
    "            if len(inp) > len(tar):\n",
    "                padding = [word_id_map[EOS]] + [word_id_map[PAD]]*(len(inp) - len(tar)-1)\n",
    "                tar += padding\n",
    "\n",
    "            if len(inp) == len(tar):\n",
    "                print(len(inp), len(tar))\n",
    "                train.append(\n",
    "                    [tar, tar]\n",
    "                )\n",
    "\n",
    "    return train[0: int(len(train)*TRAIN_SIZE)],\\\n",
    "        train[int(len(train)*TRAIN_SIZE): -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  CHAINER DRIVER FOR LOSS REPORTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './character-rnn-chainer/dataset/news_summary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f844ba25d2b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_id_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_word_id_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_id_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_id_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-7b0c767331d8>\u001b[0m in \u001b[0;36mgen_word_id_map\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_word_id_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mword_id_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './character-rnn-chainer/dataset/news_summary.csv'"
     ]
    }
   ],
   "source": [
    "word_id_map = gen_word_id_map(DS_PATH)\n",
    "VOCAB_SIZE = len(word_id_map)\n",
    "\n",
    "\n",
    "train_set, val_set = gen_dataset(word_id_map, DS_PATH)\n",
    "\n",
    "\n",
    "attention_model = GlobalAttention(NUM_HIDDEN)\n",
    "model = EncoderDecoder(\n",
    "            NUM_ENCODE_LAYERS,\n",
    "            NUM_DECODE_LAYERS,\n",
    "            NUM_HIDDEN,\n",
    "            VOCAB_SIZE,\n",
    "            DROPOUT\n",
    "        )\n",
    "model = Seq2SeqClassifier(model)\n",
    "\n",
    "\n",
    "xp = np\n",
    "\n",
    "\n",
    "# OPTIMIZER\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(\n",
    "    chainer.optimizer.GradientClipping(GRADIENT_CLIP)\n",
    ")\n",
    "\n",
    "\n",
    "# DS ITERATORS.\n",
    "train_iter = Seq2SeqIterator(\n",
    "    xp,\n",
    "    train_set,\n",
    "    BATCH_SIZE,\n",
    "    word_id_map[EOS],\n",
    "    word_id_map[PAD],\n",
    "    shuffle=False,\n",
    "    repeat=True\n",
    ")\n",
    "\n",
    "val_iter = Seq2SeqIterator(\n",
    "    xp,\n",
    "    val_set,\n",
    "    BATCH_SIZE,\n",
    "    word_id_map[EOS],\n",
    "    word_id_map[PAD],\n",
    "    shuffle=False,\n",
    "    repeat=False\n",
    ")\n",
    "\n",
    "\n",
    "# UPDATER\n",
    "updater = Seq2SeqUpdater(\n",
    "    train_iter,\n",
    "    optimizer,\n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "\n",
    "# TRAINER\n",
    "trainer = training.Trainer(\n",
    "    updater,\n",
    "    stop_trigger=(NUM_EPOCHS, \"epoch\"),\n",
    "    out=LOG\n",
    ")\n",
    "\n",
    "\n",
    "# EXTENSIONS.\n",
    "trainer.extend(\n",
    "    extensions.Evaluator(\n",
    "        val_iter, model, device=DEVICE,\n",
    "        eval_func=lambda batch: model(batch[0], batch[1], train=False)\n",
    "    )\n",
    ")\n",
    "\n",
    "interval = 1\n",
    "\n",
    "trainer.extend(\n",
    "    extensions.LogReport(\n",
    "        postprocess=lambda result: compute_loss(result, TRAIN_SIZE),\n",
    "        trigger=(interval, \"epoch\")\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer.extend(\n",
    "    extensions.PrintReport(\n",
    "        [\n",
    "            \"epoch\", \"iteration\",\n",
    "            \"train_loss\", \"train_acc\",\n",
    "            \"val_loss\", \"val_acc\"\n",
    "        ]\n",
    "    ),\n",
    "    trigger=(interval, \"epoch\")\n",
    ")\n",
    "\n",
    "trainer.extend(\n",
    "    extensions.ProgressBar(update_interval=1)\n",
    ")\n",
    "\n",
    "trainer.extend(\n",
    "    extensions.snapshot(trigger=(interval, \"epoch\"))\n",
    ")\n",
    "\n",
    "trainer.extend(\n",
    "    extensions.snapshot_object(model, \"model_epoch_{.updater.epoch}\")\n",
    ")\n",
    "\n",
    "trainer.run()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
